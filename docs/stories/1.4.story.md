# Story 1.4: Metadata Indexing & Record Verification API

## Status
Ready for Review

## Story
**As a** backend developer,
**I want** to monitor registration events and expose query interfaces,
**so that** frontend and platform operations can retrieve account information and verify off-chain profile hashes.

## Acceptance Criteria
1. Monitor `SellerRegistered` / `WarehouseRegistered` events and write to Postgres
2. Provide REST/BFF interface returning account profiles (address, role, hash, registration time)
3. Implement hash verification API to recalculate off-chain profile hashes and compare with on-chain
4. Integration tests covering event consumption, database writes, and hash verification flows
5. Validate 上述交付在 Docker Compose PoC 环境中端到端运行，按《docs/architecture/6-部署与环境.md#61-本地-docker-poc-环境》完成 Postgres/Hasura 启动与健康检查，并确认宿主机 BFF/Web 能稳定连接

## Tasks / Subtasks
- [x] Validate Docker Compose PoC environment (AC: 5)
  - [x] 创建或更新 `docker/compose.poc.yml`，仅包含 Postgres 与 Hasura 服务，配置参考《docs/architecture/6-部署与环境.md#61-本地-docker-poc-环境》 [Source: docs/architecture/6-部署与环境.md]
  - [x] 启动 Compose，确认 `postgres`、`hasura` 容器处于 `Up`／`Up (healthy)` 状态，并记录健康检查方式（`docker compose ps`、`http://localhost:8080/console`）[Source: docs/architecture/6-部署与环境.md]
  - [x] 在宿主机配置并验证 BFF 所需环境变量（`DATABASE_URL=postgres://haigo:haigo@localhost:5433/haigo`、`HASURA_URL=http://localhost:8080`、`APTOS_INDEXER_URL=https://api.testnet.aptoslabs.com/v1/graphql`），确保服务连通 [Source: docs/architecture/4-链下服务与数据流.md]
  - [x] 将 Docker 配置对交付的影响记录在 Story Change Log，并引用更新后的文档链接 [Source: docs/architecture/6-部署与环境.md]
- [x] Set up Aptos Indexer event monitoring (AC: 1)
  - [x] Create event listener service in `apps/bff/src/modules/accounts/` to consume `SellerRegistered` and `WarehouseRegistered` events from official Aptos Indexer GraphQL endpoint (`https://api.testnet.aptoslabs.com/v1/graphql`) [Source: docs/architecture/4-链下服务与数据流.md#4-1-2-事件轮询-游标管理]
  - [x] Implement GraphQL query filtering by event type `"0xHAIGO::registry::SellerRegistered"` and `"0xHAIGO::registry::WarehouseRegistered"` with pagination support [Source: docs/architecture/4-链下服务与数据流.md#4-1-2-事件轮询-游标管理]
  - [x] Add event deduplication logic using `txn_version + event_index` combination to prevent duplicate processing [Source: docs/architecture/4-链下服务与数据流.md#4-2-数据模型-prisma-postgres]
- [x] Implement Postgres account storage (AC: 1)
  - [x] Create `accounts` table with columns: `account_address` (PK), `role` ('seller'|'warehouse'), `profile_hash_algo` ('blake3'), `profile_hash_value` (64-char hex), `profile_uri`, `txn_version`, `event_index`, `chain_timestamp` [Source: docs/architecture/4-链下服务与数据流.md#4-2-数据模型-prisma-postgres]
  - [x] Add unique index on `(txn_version, event_index)` to enforce event deduplication and index on `account_address` for fast lookups [Source: docs/architecture/4-链下服务与数据流.md#4-2-数据模型-prisma-postgres]
  - [x] Implement AccountsRepository using Prisma (via `PrismaService`) with methods: `createAccount()`, `findByAddress()`, `updateProfile()` [Source: docs/architecture/4-链下服务与数据流.md#4-4-核心模块]
- [x] Create BFF REST API endpoints (AC: 2)
  - [x] Implement `GET /api/accounts/:address` endpoint returning `AccountProfile` DTO with fields: address, role, profileHash {algo, value}, profileUri, registeredAt (ISO timestamp), and optional `orderCount` when aggregate data is available [Source: docs/architecture/4-链下服务与数据流.md#4-3-rest-api-已实现]
  - [x] Add accounts controller in `apps/bff/src/modules/accounts/accounts.controller.ts` with proper error handling for non-existent addresses (404) and validation errors (400) [Source: docs/architecture/4-链下服务与数据流.md#4-4-核心模块]
  - [x] Include response metadata with `requestId`, `timestamp` and `x-haigo-trace-id` header for tracing [Source: docs/architecture/4-链下服务与数据流.md#4-3-rest-api-已实现]
- [x] Implement hash verification API (AC: 3)
  - [x] Create `POST /api/accounts/:address/verify-hash` endpoint that accepts media file upload and recalculates the BLAKE3 hash server-side against the stored `profile_hash_value` [Source: docs/architecture/4-链下服务与数据流.md#4-2-数据模型-prisma-postgres]
  - [x] Add BLAKE3 hash computation using the same library as frontend (64-character lowercase hex output) and compare with on-chain stored hash [Source: docs/architecture/4-链下服务与数据流.md#4-2-数据模型-prisma-postgres]
  - [x] Return verification result with boolean `verified`, `computedHash`, `storedHash`, and timestamp for audit purposes [Source: docs/architecture/4-链下服务与数据流.md#4-3-rest-api-已实现]
- [x] Add Hasura GraphQL integration (AC: 2)
  - [x] Configure Hasura to track `accounts` table and define query collection for `accountByAddress($address: String!)` [Source: docs/architecture/4-链下服务与数据流.md#4-5-配置与环境变量]
  - [x] Set up `anonymous` role with read-only access to accounts queries and `operations` role with aggregate permissions for admin operations [Source: docs/architecture/4-链下服务与数据流.md#4-5-配置与环境变量]
  - [x] Add manual relationship between `accounts.account_address` and future `orders.creator_address`/`orders.warehouse_address` for cross-entity queries [Source: docs/architecture/4-链下服务与数据流.md#4-2-数据模型-prisma-postgres]
- [x] Testing and validation (AC: 4, AC: 5)
  - [x] Write unit tests for event processing logic, account repository methods, and API endpoints using Jest with mocked Indexer responses [Source: docs/runbook.md#8-测试策略]
  - [x] Add integration tests covering end-to-end flow: mock event → database write → API retrieval → hash verification，并在 Docker Compose 环境中执行验证 [Source: docs/runbook.md#8-测试策略]
  - [x] Test error scenarios: malformed events, duplicate processing, database failures, invalid addresses, hash mismatches [Source: docs/runbook.md#8-测试策略]
  - [x] Ensure `docker compose exec bff pnpm --filter @haigo/bff test`（或等效命令）通过，记录执行截图/日志于 Debug Log [Source: docs/runbook.md#8-测试策略]

## Dev Notes
- **Previous Story Insights**: Story 1.3 implements wallet connection and registration flow using `register_seller`/`register_warehouse` functions that emit `SellerRegistered`/`WarehouseRegistered` events with BLAKE3 hashed profile data; this story must consume those events to maintain synchronized off-chain records. [Source: docs/stories/1.3.story.md]
- **Data Models**: Use `AccountProfile` DTO structure defined in `packages/shared/src/dto` with fields: `address: string`, `role: 'seller'|'warehouse'`, `profileHash: {algo: 'blake3'; value: string}`, `profileUri?: string`, `registeredAt: string` (ISO timestamp), and optional `orderCount?: number`. Hash values must be 64-character lowercase hex strings computed using BLAKE3 algorithm. [Source: packages/shared/src/dto/registry.ts]
- **API Specifications**:
  - `GET /api/accounts/:address` returns account profile with registration details and optional order count aggregation
  - `orderCount` should come from Hasura aggregates: for sellers, count `orders_aggregate(where: {creator_address: {_eq: :address}})`; for warehouses, count `orders_aggregate(where: {warehouse_address: {_eq: :address}})`.
  - `POST /api/accounts/:address/verify-hash` accepts multipart file upload and returns hash verification results
  - All responses include `meta.requestId`, `meta.timestamp` and `x-haigo-trace-id` header for tracing
  - Error responses follow `code/message/details` format [Source: docs/architecture/4-链下服务与数据流.md#4-3-rest-api-已实现]
- **Component Specifications**:
  - Use NestJS modular structure with Controller/Service/Repository pattern in `apps/bff/src/modules/accounts/`
  - Event listener service should poll the Aptos Indexer GraphQL endpoint periodically; begin with a 30-second interval as a tunable default to balance freshness and rate limits, and document any agreed adjustments (or switch to webhooks when available).
  - Hash verification service must use identical BLAKE3 implementation as frontend for consistency [Source: docs/architecture/4-链下服务与数据流.md#4-4-核心模块]
- **File Locations**:
  - Event monitoring: `apps/bff/src/modules/accounts/event-listener.service.ts`
  - Data access: `apps/bff/src/modules/accounts/accounts.repository.ts`
  - API controller: `apps/bff/src/modules/accounts/accounts.controller.ts`
  - Business logic: `apps/bff/src/modules/accounts/accounts.service.ts`
  - Database schema: Migration files in `apps/bff/prisma/migrations/` or equivalent ORM directory
  - Shared types: Import `AccountProfile` and related DTOs from `packages/shared/src/dto/index.ts` (re-exported via the DTO registry) to stay aligned with shared typing. [Source: docs/architecture/high-level-architecture.md#repository-structure]
- **Testing Requirements**:
  - Unit tests using Jest framework covering service methods, repository operations, and controller endpoints
  - Integration tests with mocked Aptos Indexer GraphQL responses using test fixtures
  - Database tests using in-memory or test database with proper setup/teardown
  - Hash verification tests with known BLAKE3 test vectors
  - Error handling tests for network failures, database errors, and malformed data [Source: docs/runbook.md#8-测试策略]
- **Technical Constraints**:
  - Event processing must be idempotent using `txn_version + event_index` deduplication to handle reprocessing scenarios
  - BLAKE3 hash computation must produce identical results to frontend implementation (64-char lowercase hex)
  - Database writes must be atomic to prevent partial state updates during event processing
  - API responses must handle non-existent addresses gracefully (404) vs system errors (500)
  - Aptos Indexer queries must include proper error handling and retry logic for network failures [Source: docs/architecture/4-链下服务与数据流.md#4-2-数据模型-prisma-postgres]
- **Performance Requirements**:
  - Treat a 30-second polling cadence as the starting baseline; refine it with Ops once real Indexer rate limits are confirmed.
  - Database queries must use appropriate indexes for address lookups and event deduplication
  - Aim for hash verification responses within 5 seconds for files up to 15MB and capture metrics to validate the target
  - Target sub-500ms latency for standard API queries; log performance data and adjust thresholds with PO/Ops as needed
- **Project Structure Notes**: Implementation should follow established BFF modular architecture with separation of concerns between event processing, data access, and API layers. No structural deviations expected from existing patterns. [Source: docs/architecture/high-level-architecture.md#repository-structure]

### Testing
- **Framework Setup**: Use Jest with NestJS testing utilities, include @nestjs/testing for module testing and supertest for HTTP endpoint testing
- **Test Coverage Requirements**:
  - Event listener service with mocked Aptos Indexer GraphQL responses
  - Account repository CRUD operations with test database
  - API controllers with request/response validation
  - Hash verification logic with known BLAKE3 test vectors
  - Error scenarios and edge cases (duplicate events, network failures, invalid data)
- **Commands**:
  1. `docker compose -f docker/compose.poc.yml up -d`（首次运行需拉取镜像，确认 `postgres`、`hasura` 均为 `Up`）
  2. `pnpm --filter @haigo/bff test` 在宿主机执行单元与集成测试；必要时追加 `--runInBand` 以降低资源占用
  3. `pnpm --filter @haigo/bff lint`（可选）验证代码质量；完成后使用 `docker compose logs hasura` 查看服务状态
  4. 若需清理环境：`docker compose -f docker/compose.poc.yml down --remove-orphans`
- **Database Testing**: Use test database or in-memory SQLite for repository tests with proper schema setup and data cleanup between tests
- **Mock Strategy**: Mock Aptos Indexer GraphQL client responses using Jest mocks with realistic event data fixtures matching production schema [Source: docs/runbook.md#8-测试策略]

## Change Log
| Date       | Version | Description     | Author |
| ---------- | ------- | ---------------- | ------ |
| 2025-09-17 | v0.1    | Initial draft   | Bob |
| 2025-09-17 | v0.2    | Implemented indexer ingestion, REST/verification APIs, Hasura metadata, and Jest test suite | James |
| 2025-09-18 | v0.3    | 调整 Compose 指引并验证 Postgres/Hasura 容器健康检查流程 | James |
| 2025-09-18 | v0.4    | 宿主机配置 BFF 环境变量，跑通 prisma migrate + tests，记录新的文档引用 | James |

## Dev Agent Record
### Agent Model Used

- GPT-5 (Codex)

### Debug Log References

- apps/bff/test/accounts.integration.spec.ts
- apps/bff/test/accounts.service.spec.ts
- pnpm --filter @haigo/bff test

### Completion Notes List

- Implemented Prisma-backed accounts repository with idempotent event ingestion and cursor resume.
- Exposed NestJS controller/service covering profile retrieval, BLAKE3 hash verification, and Hasura order aggregates with tracing metadata.
- Added Hasura metadata (table tracking, permissions, query collection) and comprehensive Jest unit/integration coverage for repository, listener, service, controller flows.

### File List

- apps/bff/prisma/schema.prisma
- apps/bff/prisma/migrations/20240610_create_accounts_table/migration.sql
- apps/bff/src/infrastructure/prisma/prisma.service.ts
- apps/bff/src/modules/accounts/*
- apps/bff/src/common/configuration.ts
- apps/bff/src/modules/app.module.ts
- apps/bff/src/shared/dto/registry.ts
- apps/bff/package.json
- apps/bff/jest.config.ts
- apps/bff/tsconfig.json
- apps/bff/tsconfig.spec.json
- apps/bff/test/*.spec.ts
- hasura/metadata/**

## QA Results

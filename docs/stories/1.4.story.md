# Story 1.4: Metadata Indexing & Record Verification API

## Status
Draft

## Story
**As a** backend developer,
**I want** to monitor registration events and expose query interfaces,
**so that** frontend and platform operations can retrieve account information and verify off-chain profile hashes.

## Acceptance Criteria
1. Monitor `SellerRegistered` / `WarehouseRegistered` events and write to Postgres
2. Provide REST/BFF interface returning account profiles (address, role, hash, registration time)
3. Implement hash verification API to recalculate off-chain profile hashes and compare with on-chain
4. Integration tests covering event consumption, database writes, and hash verification flows

## Tasks / Subtasks
- [ ] Set up Aptos Indexer event monitoring (AC: 1)
  - [ ] Create event listener service in `apps/bff/src/modules/accounts/` to consume `SellerRegistered` and `WarehouseRegistered` events from official Aptos Indexer GraphQL endpoint (`https://api.testnet.aptoslabs.com/v1/graphql`) [Source: docs/architecture/4-链下服务与数据流.md#41-bff-media-ingestor]
  - [ ] Implement GraphQL query filtering by event type `"0xHAIGO::registry::SellerRegistered"` and `"0xHAIGO::registry::WarehouseRegistered"` with pagination support [Source: docs/architecture/4-链下服务与数据流.md#41-bff-media-ingestor]
  - [ ] Add event deduplication logic using `txn_version + event_index` combination to prevent duplicate processing [Source: docs/architecture/4-链下服务与数据流.md#42-数据模型定义]
- [ ] Implement Postgres account storage (AC: 1)
  - [ ] Create `accounts` table with columns: `account_address` (PK), `role` ('seller'|'warehouse'), `profile_hash_algo` ('blake3'), `profile_hash_value` (64-char hex), `profile_uri`, `txn_version`, `event_index`, `chain_timestamp` [Source: docs/architecture/4-链下服务与数据流.md#42-数据模型定义]
  - [ ] Add unique index on `(txn_version, event_index)` to enforce event deduplication and index on `account_address` for fast lookups [Source: docs/architecture/4-链下服务与数据流.md#42-数据模型定义]
  - [ ] Implement AccountsRepository using Prisma/TypeORM with methods: `createAccount()`, `findByAddress()`, `updateProfile()` [Source: docs/architecture/4-链下服务与数据流.md#46-核心接口与类设计]
- [ ] Create BFF REST API endpoints (AC: 2)
  - [ ] Implement `GET /api/accounts/:address` endpoint returning `AccountProfile` DTO with fields: address, role, profileHash {algo, value}, profileUri, registeredAt (ISO timestamp), orderCount [Source: docs/architecture/4-链下服务与数据流.md#44-bff-api-接口规范]
  - [ ] Add accounts controller in `apps/bff/src/modules/accounts/accounts.controller.ts` with proper error handling for non-existent addresses (404) and validation errors (400) [Source: docs/architecture/4-链下服务与数据流.md#46-核心接口与类设计]
  - [ ] Include response metadata with `requestId`, `timestamp` and `x-haigo-trace-id` header for tracing [Source: docs/architecture/4-链下服务与数据流.md#44-bff-api-接口规范]
- [ ] Implement hash verification API (AC: 3)
  - [ ] Create `POST /api/accounts/:address/verify-hash` endpoint that accepts media file upload and recalculates BLAKE3 hash client-side vs stored `profile_hash_value` [Source: docs/architecture/4-链下服务与数据流.md#42-数据模型定义]
  - [ ] Add BLAKE3 hash computation using the same library as frontend (64-character lowercase hex output) and compare with on-chain stored hash [Source: docs/architecture/4-链下服务与数据流.md#42-数据模型定义]
  - [ ] Return verification result with boolean `verified`, `computedHash`, `storedHash`, and timestamp for audit purposes [Source: docs/architecture/4-链下服务与数据流.md#44-bff-api-接口规范]
- [ ] Add Hasura GraphQL integration (AC: 2)
  - [ ] Configure Hasura to track `accounts` table and define query collection for `accountByAddress($address: String!)` [Source: docs/architecture/4-链下服务与数据流.md#45-hasura-graphql-摘要]
  - [ ] Set up `anonymous` role with read-only access to accounts queries and `operations` role with aggregate permissions for admin operations [Source: docs/architecture/4-链下服务与数据流.md#45-hasura-graphql-摘要]
  - [ ] Add manual relationship between `accounts.account_address` and future `orders.creator_address`/`orders.warehouse_address` for cross-entity queries [Source: docs/architecture/4-链下服务与数据流.md#42-数据模型定义]
- [ ] Testing and validation (AC: 4)
  - [ ] Write unit tests for event processing logic, account repository methods, and API endpoints using Jest with mocked Indexer responses [Source: docs/runbook.md#8-测试策略]
  - [ ] Add integration tests covering end-to-end flow: mock event → database write → API retrieval → hash verification [Source: docs/runbook.md#8-测试策略]
  - [ ] Test error scenarios: malformed events, duplicate processing, database failures, invalid addresses, hash mismatches [Source: docs/runbook.md#8-测试策略]
  - [ ] Ensure `npm run test --workspace apps/bff` passes and covers event consumption, data writes, and verification flows [Source: docs/runbook.md#8-测试策略]

## Dev Notes
- **Previous Story Insights**: Story 1.3 implements wallet connection and registration flow using `register_seller`/`register_warehouse` functions that emit `SellerRegistered`/`WarehouseRegistered` events with BLAKE3 hashed profile data; this story must consume those events to maintain synchronized off-chain records. [Source: docs/stories/1.3.story.md]
- **Data Models**: Use `AccountProfile` DTO structure defined in `packages/shared/src/dto` with exact fields: `address: string`, `role: 'seller'|'warehouse'`, `profileHash: {algo: 'blake3'; value: string}`, `profileUri?: string`, `registeredAt: string` (ISO timestamp). Hash values must be 64-character lowercase hex strings computed using BLAKE3 algorithm. [Source: docs/architecture/4-链下服务与数据流.md#46-核心接口与类设计]
- **API Specifications**:
  - `GET /api/accounts/:address` returns account profile with registration details and order count aggregation
  - `orderCount` should come from the Hasura order aggregate for the given address (`orders_aggregate(where: {account_address: {_eq: :address}})`); if Hasura is unavailable, fall back to Indexer order events while preserving the same response shape and document the interim approach for QA.
  - `POST /api/accounts/:address/verify-hash` accepts multipart file upload and returns hash verification results
  - All responses include `meta.requestId`, `meta.timestamp` and `x-haigo-trace-id` header for tracing
  - Error responses follow `code/message/details` format [Source: docs/architecture/4-链下服务与数据流.md#44-bff-api-接口规范]
- **Component Specifications**:
  - Use NestJS modular structure with Controller/Service/Repository pattern in `apps/bff/src/modules/accounts/`
  - Event listener service should poll the Aptos Indexer GraphQL endpoint periodically; begin with a 30-second interval as a tunable default to balance freshness and rate limits, and document any agreed adjustments (or switch to webhooks when available).
  - Hash verification service must use identical BLAKE3 implementation as frontend for consistency [Source: docs/architecture/4-链下服务与数据流.md#46-核心接口与类设计]
- **File Locations**:
  - Event monitoring: `apps/bff/src/modules/accounts/event-listener.service.ts`
  - Data access: `apps/bff/src/modules/accounts/accounts.repository.ts`
  - API controller: `apps/bff/src/modules/accounts/accounts.controller.ts`
  - Business logic: `apps/bff/src/modules/accounts/accounts.service.ts`
  - Database schema: Migration files in `apps/bff/prisma/migrations/` or equivalent ORM directory
  - Shared types: Import `AccountProfile` and related DTOs from `packages/shared/src/dto/index.ts` (re-exported via the DTO registry) to stay aligned with shared typing. [Source: docs/architecture/high-level-architecture.md#repository-structure]
- **Testing Requirements**:
  - Unit tests using Jest framework covering service methods, repository operations, and controller endpoints
  - Integration tests with mocked Aptos Indexer GraphQL responses using test fixtures
  - Database tests using in-memory or test database with proper setup/teardown
  - Hash verification tests with known BLAKE3 test vectors
  - Error handling tests for network failures, database errors, and malformed data [Source: docs/runbook.md#8-测试策略]
- **Technical Constraints**:
  - Event processing must be idempotent using `txn_version + event_index` deduplication to handle reprocessing scenarios
  - BLAKE3 hash computation must produce identical results to frontend implementation (64-char lowercase hex)
  - Database writes must be atomic to prevent partial state updates during event processing
  - API responses must handle non-existent addresses gracefully (404) vs system errors (500)
  - Aptos Indexer queries must include proper error handling and retry logic for network failures [Source: docs/architecture/4-链下服务与数据流.md#42-数据模型定义]
- **Performance Requirements**:
  - Treat a 30-second polling cadence as the starting baseline; refine it with Ops once real Indexer rate limits are confirmed.
  - Database queries must use appropriate indexes for address lookups and event deduplication
  - Aim for hash verification responses within 5 seconds for files up to 15MB and capture metrics to validate the target
  - Target sub-500ms latency for standard API queries; log performance data and adjust thresholds with PO/Ops as needed
- **Project Structure Notes**: Implementation should follow established BFF modular architecture with separation of concerns between event processing, data access, and API layers. No structural deviations expected from existing patterns. [Source: docs/architecture/high-level-architecture.md#repository-structure]

### Testing
- **Framework Setup**: Use Jest with NestJS testing utilities, include @nestjs/testing for module testing and supertest for HTTP endpoint testing
- **Test Coverage Requirements**:
  - Event listener service with mocked Aptos Indexer GraphQL responses
  - Account repository CRUD operations with test database
  - API controllers with request/response validation
  - Hash verification logic with known BLAKE3 test vectors
  - Error scenarios and edge cases (duplicate events, network failures, invalid data)
- **Commands**: Execute `npm run test --workspace apps/bff`; add a dedicated integration test command once a `test:e2e` script is introduced
- **Database Testing**: Use test database or in-memory SQLite for repository tests with proper schema setup and data cleanup between tests
- **Mock Strategy**: Mock Aptos Indexer GraphQL client responses using Jest mocks with realistic event data fixtures matching production schema [Source: docs/runbook.md#8-测试策略]

## Change Log
| Date       | Version | Description     | Author |
| ---------- | ------- | ---------------- | ------ |
| 2025-09-17 | v0.1    | Initial draft   | Bob |

## Dev Agent Record
### Agent Model Used

### Debug Log References

### Completion Notes List

### File List

## QA Results

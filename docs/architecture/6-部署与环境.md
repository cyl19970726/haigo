# 6. 部署与环境

本章按“先设置环境→再运行程序”的顺序，精简说明本地/测试网的统一做法，并给出 BFF 监听参数与 API Key 的放置位置。

## 6.1 设置环境

1) 安装依赖
- Node ≥ 18（建议 20 LTS）
- pnpm ≥ 8.15
- 可选全局工具：`aptos`、`hasura-cli`、`prisma`（便于调试）
- 安装 workspace 依赖：
```bash
pnpm install
```

2) 环境变量放置（统一使用仓库根 `.env.local`）
- 为避免到处散落 `.env` 文件，BFF 已配置同时加载以下文件（后者优先级更高）：
  - `apps/bff/.env`（可选，存在则读取）
  - `./.env`（仓库根，可选）
  - `./.env.local`（仓库根，推荐放置）
- 建议放到仓库根的 `.env.local`，Web 与 BFF 可共用；示例：
```env
# Aptos endpoints（测试网，统一走 Aptos Labs 网关）
APTOS_INDEXER_URL=https://api.testnet.aptoslabs.com/v1/graphql
APTOS_NODE_API_URL=https://api.testnet.aptoslabs.com/v1
# 可选：如使用 API Key，BFF 会同时发送：
#   Authorization: Bearer <key>
#   x-aptos-api-key: <key>
# APTOS_NODE_API_KEY=aptoslabs_...

# 数据库 / Hasura （本地 Docker 示例）
DATABASE_URL=postgres://haigo:haigo@localhost:5433/haigo
HASURA_URL=http://localhost:8080

# BFF 监听参数（R1 注册事件）
ACCOUNT_INGESTOR_INTERVAL_MS=30000   # 30s
ACCOUNT_INGESTOR_PAGE_SIZE=25        # 每次批量抓取的事件条数（越小越省配额）

# Web 端
NEXT_PUBLIC_BFF_URL=http://localhost:3001
NEXT_PUBLIC_APTOS_NETWORK=testnet
```

3) （可选）本地 Docker（Postgres + Hasura）
- 按需启动 `docker/compose.poc.yml` 提供数据库与 GraphQL 服务。

---

## 6.2 运行程序

1) 仅运行 BFF
```bash
pnpm --filter @haigo/shared build
pnpm --filter @haigo/bff build
pnpm --filter @haigo/bff start
```
- BFF 会自动从仓库根 `.env.local`（或 `apps/bff/.env`）读取上述变量。
- 若 Indexer 限流/超时，BFF 会自动退避降频；兜底用 Fullnode by_version 获取 txn hash。

2) 仅运行 Web
```bash
pnpm --filter @haigo/web dev
```
- Next.js 读取的是前端应用目录下的 `.env.local`（此项目为 `apps/web/.env.local`）。根目录 `.env.local` 仅供 BFF/脚本使用。

3) 同时运行（开发模式）
```bash
pnpm --filter @haigo/shared build --watch &
pnpm --filter @haigo/bff start:dev &
pnpm --filter @haigo/web dev
```

说明：
- “监听间隔 interval”指 BFF 访问 Indexer 的轮询频率（默认 30s）。
- “size（pageSize）”指单次 GraphQL 查询返回的事件条数上限，越小越省配额，但需要更多轮次才能追平历史事件。当前默认 25。

---

## 6.3 本地 Docker PoC 环境（Postgres + Hasura）

> PoC 阶段我们仅将 **Postgres** 与 **Hasura** 放入 Docker，确保数据库与 GraphQL 元数据在团队内一致；BFF、Web 仍在宿主机运行，方便热更新与调试。

### 6.1.1 前置依赖

| 项目 | 说明 |
| ---- | ---- |
| Docker Engine ≥ 24 | 推荐安装 Docker Desktop（macOS/Windows）或原生 Docker CE（Linux）。 |
| Docker Compose V2 | 随 Docker Desktop 自带，Linux 可通过 `docker compose version` 验证。 |
| pnpm ≥ 8.15 | 宿主机运行 Node 服务与脚本。 |
| Hasura CLI ≥ v2.44 | 导入 metadata，命令：`npm install -g hasura-cli`。 |
| Node.js ≥ 18 | 宿主机运行 BFF、Web 及工具链。 |

### 6.1.2 Compose 模板

`docker/compose.poc.yml`（仓库已提供示例）仅包含数据库与 Hasura：

```yaml
services:
  postgres:
    image: postgres:15
    container_name: haigo-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: haigo
      POSTGRES_PASSWORD: haigo
      POSTGRES_DB: haigo
    ports:
      - "5433:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data

  hasura:
    image: hasura/graphql-engine:v2.44.0
    container_name: haigo-hasura
    restart: unless-stopped
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    environment:
      HASURA_GRAPHQL_DATABASE_URL: postgres://haigo:haigo@postgres:5432/haigo
      HASURA_GRAPHQL_ENABLE_CONSOLE: "true"
      HASURA_GRAPHQL_DEV_MODE: "true"
      HASURA_GRAPHQL_ADMIN_SECRET: haigo-secret
      HASURA_GRAPHQL_JWT_SECRET: '{"type":"HS256","key":"local-development-secret-key-32-bytes"}'

volumes:
  pg_data:
```

> 默认将容器端口映射为 `5433→5432`、`8080→8080`，避免与本地 Postgres 冲突；需要时可再自定义端口。

### 6.1.3 启动与健康检查

```bash
cd docker
docker compose -f compose.poc.yml up -d
docker compose -f compose.poc.yml ps
```

服务就绪的判定：
- `postgres` 状态为 `Up`；
- `hasura` 状态为 `Up (healthy)`，访问 http://localhost:8080/console 可登录（Admin Secret: `haigo-secret`）。

常用命令：

| 目标 | 命令 |
| ---- | ---- |
| 查看服务日志 | `docker compose -f compose.poc.yml logs -f hasura` |
| 进入数据库容器 | `docker exec -it haigo-postgres psql -U haigo haigo` |
| 重启 Hasura | `docker compose -f compose.poc.yml restart hasura` |
| 停止并移除环境 | `docker compose -f compose.poc.yml down --remove-orphans` |
| 清空数据库数据 | `docker volume rm docker_pg_data` |

### 6.1.4 数据初始化

1. **Prisma 迁移（宿主机执行）**
   ```bash
   export DATABASE_URL="postgres://haigo:haigo@localhost:5433/haigo"
   pnpm --filter @haigo/bff prisma:migrate:deploy
   ```
   迁移完成后确认 `MEDIA_STORAGE_DIR`（默认 `./storage/media`）指向可写目录，必要时执行 `mkdir -p storage/media && chmod 755 storage/media`。
   如需重置数据库：`pnpm --filter @haigo/bff prisma migrate reset` 或删除卷。

2. **Hasura Metadata 导入**
   ```bash
   export HASURA_GRAPHQL_ENDPOINT="http://localhost:8080"
   export HASURA_GRAPHQL_ADMIN_SECRET="haigo-secret"

   hasura metadata apply \
     --project hasura \
     --endpoint "$HASURA_GRAPHQL_ENDPOINT" \
     --admin-secret "$HASURA_GRAPHQL_ADMIN_SECRET"
   ```
   导入后可在 Hasura Console 检查 `accounts` 等表、权限配置与 Query Collection。

### 6.1.5 常见问题

1. **端口冲突**：默认 `5433:5432` 已规避常见冲突，如仍占用可改成 `5434:5432` 等；Hasura 端口同理。
2. **Hasura 连不上数据库**：确认环境变量 `HASURA_GRAPHQL_DATABASE_URL` 是否与 Postgres 账号匹配，必要时查看 `docker compose logs hasura`。
3. **Prisma 连接失败**：确认宿主机 `DATABASE_URL` 指向 `localhost:5433`，并已执行迁移。
4. **元数据不一致**：重新运行 Hasura CLI 导入，或执行 `hasura metadata reload`。

### 6.1.6 Epic 2 附加组件：订单监听与媒体存储

为满足 Epic 2 的订单生命周期与媒体存证需求，本地环境需补充以下组件与准备步骤：

- **对象存储 / 媒体目录**：
  - PoC 可继续使用本地文件系统，执行 `mkdir -p storage/media` 并在 `.env` 内配置 `MEDIA_STORAGE_DIR=./storage/media`（可选 `MEDIA_PUBLIC_PREFIX=/media` 暴露静态路径）。
  - 若需模拟 Story 2.3 的对象存储，可新增 MinIO 服务（端口 `9000/9001`），并在 BFF 配置 `MEDIA_STORAGE_ENDPOINT`、`MEDIA_BUCKET`。上传凭证由 BFF 统一管理。
- **媒体静态访问**：使用 Nginx 或 Node 静态服务暴露 `storage/media`，以便前端轮询哈希校验。PoC 示例：`pnpm --filter @haigo/bff serve:media`（待补齐脚本）。
- **订单事件监听**：BFF 在启动时会并行运行 `AccountsEventListener` 与计划中的 `OrdersEventListener`。确保 `ORDER_INGESTOR_INTERVAL_MS`、`ORDER_INGESTOR_PAGE_SIZE` 环境变量已设置，避免默认值导致索引过慢。
- **本地调试数据**：Story 2.x 依赖链上事件；本地可通过 `scripts/seed-orders.ts`（计划新增）或测试网真实数据驱动。若暂未有脚本，可使用 Aptos CLI 手动发送订单相关交易，再由监听服务回放。

> 建议将 MinIO/静态服务单独写入 `docker/compose.media.yml`，通过 `docker compose -f compose.poc.yml -f compose.media.yml up -d` 启动，避免污染基础数据库栈。

## 6.2 宿主机运行 BFF 与 Web

- **启动命令**：
  ```bash
  pnpm --filter @haigo/bff start:dev
  pnpm --filter @haigo/web dev
  ```
- **关键环境变量**：
  - BFF：`DATABASE_URL=postgres://haigo:haigo@localhost:5433/haigo`、`HASURA_URL=http://localhost:8080`、`APTOS_INDEXER_URL=https://api.testnet.aptoslabs.com/v1/graphql`。
  - Web：`NEXT_PUBLIC_BFF_URL=http://localhost:3001`、`NEXT_PUBLIC_HASURA_URL=http://localhost:8080/v1/graphql`、`NEXT_PUBLIC_APTOS_INDEXER_URL=https://api.testnet.aptoslabs.com/v1/graphql`。
- **测试**：Story 1.4 要求在此环境下运行 `pnpm --filter @haigo/bff test` 并确保通过；必要时可使用 `pnpm --filter @haigo/bff lint` 做静态检查。

### 6.4 Epic 2 运行参数与服务约定（规划）
> 以下配置为 Epic 2+ 规划内容，代码尚未实现，保留用于后续迭代对齐。
- **新增 BFF 环境变量**：
  | 变量 | 默认值 | 说明 | 关联 Story |
  |------|--------|------|------------|
  | `ORDER_INGESTOR_INTERVAL_MS` | `30000` | 订单事件轮询间隔（毫秒） | 2.1 / 2.4 |
  | `ORDER_INGESTOR_PAGE_SIZE` | `50` | 单次抓取事件数量 | 2.1 |
  | `MEDIA_MAX_FILE_MB` | `200` | 上传文件最大限制（前后端统一） | 2.3 |
  | `MEDIA_STORAGE_ENDPOINT` | `http://localhost:9000` | MinIO/S3 访问地址 | 2.3 |
  | `MEDIA_STORAGE_BUCKET` | `haigo-media` | 媒体存储桶名称 | 2.3 |
  | `MEDIA_SIGNING_KEY` | _自定义_ | 生成上传签名的服务端密钥 | 2.3 |
  | `APTOS_MODULE_ADDRESS` | _部署输出_ | 订单/质押等 Move 模块地址 | 2.1 |
- **服务初始化**：BFF 启动后将：
  1. 校验对象存储可写入（若配置了 MinIO/S3）。
  2. 启动订单与账户事件监听器，打印最近游标，方便排查。
  3. 暴露 `/api/orders` 与 `/api/media/uploads` 端点；若缺少配置则在启动日志中给出警告。
- **前端依赖**：前端需要新增 `.env.local` 变量 `NEXT_PUBLIC_MEDIA_VERIFY_URL` 指向 BFF 的媒体验证接口，并在订单表单中读取 `MEDIA_MAX_FILE_MB` 与费用参数。
- **本地验证流程**：
  1. 通过 Move 脚本创建测试订单或使用测试网交易。
  2. 前端调用 `/api/orders/:recordUid/media-verify` 上传媒体。
  3. BFF 返回哈希匹配结果，并在 Hasura 中可查询对应订单记录。

## 6.5 测试网环境
- Aptos 合约部署到测试网，模块地址写入 `packages/shared/config/aptos.ts`。
- BFF 与 Hasura 可部署在单台云主机或 Kubernetes 节点（阿里云 ECS/ACK），开启 HTTPS。
- 媒体目录挂载云盘（ESSD），每日利用 OSS 同步脚本备份。

### 6.3.1 Move 模块部署（Testnet 脚本）
- 前置：安装 `aptos` CLI 与 `jq`；首次部署需为发布账户领取测试币（Testnet Faucet）。
- 一键部署脚本（初始化 Profile→尝试 faucet→发布→写回环境变量）：
  ```bash
  pnpm deploy:testnet
  # 或自定义 Profile：
  bash scripts/deploy_aptos_testnet.sh haigo-testnet
  ```
- Faucet（若脚本提示余额不足）：
  在 https://aptos.dev/network/faucet 使用脚本打印的地址领取测试币（1 APT 即可）。
- 发布后脚本会执行以下初始化与配置（幂等）：
  - `<addr>::registry::init_registry_entry()`
  - `<addr>::orders::init_orders_entry()`
  - `<addr>::orders::configure(address:<addr>, bool:false)`
  并自动写回仓库根 `.env.local`：
  ```env
  APTOS_NETWORK=testnet
  NEXT_PUBLIC_APTOS_MODULE=0x<发布地址>
  NEXT_PUBLIC_APTOS_ORDERS_MODULE=0x<发布地址>
  ```
- 完成后重启服务读取新配置：
  ```bash
  pnpm --filter @haigo/bff build && pnpm --filter @haigo/bff start
  pnpm --filter @haigo/web dev
  ```
- 私钥位置与安全：
  - 私钥保存在项目根 `.aptos/config.yaml`（或 `~/.aptos/config.yaml`）对应 Profile 的 `private_key` 字段。
  - 仅用于本机 CLI 发布。BFF/Web 运行不需要私钥；请勿将私钥写入 `.env.local`，更不要以 `NEXT_PUBLIC_` 变量暴露给前端。
  - 若需 CI 自动化发布，将私钥配置到 CI Secrets，通过脚本注入，避免提交到仓库。

### 6.3.2 媒体存储与对象服务（Story 2.3）
- 生产/测试环境推荐使用阿里云 OSS；若仍在 PoC，可使用 MinIO 或 Ceph S3。配置项：
  - IAM/STS 凭证存放在云端 Secret Manager，通过容器环境变量注入。
  - 媒体文件命名规范：`{record_uid}/{event_type}/{originalName}`。
  - 采用生命周期规则自动清理超过 `90` 天未匹配的临时文件。
- 配置 CDN 或 CloudFront 加速访问，避免前端在媒体验证时遭遇跨域或网络瓶颈。

### 6.3.3 订单索引与监控（Story 2.4）
- 为 BFF 部署 Prometheus/Grafana 指标：`order_listener_last_version`、`order_listener_error_total`。
- 配置告警规则：监听超过 10 分钟无新事件或错误率 > 5% 时通知运营。
- 定期（CRON）运行 `scripts/backfill-order-media.ts`，补齐链上存在但链下缺失的媒体记录。

## 6.4 CI/CD
1. GitHub Actions（或阿里云流水线）三阶段：`move-test`、`backend-test`、`frontend-build`。
2. 构建产物：Move 模块 `build/`、BFF Docker 镜像、Next.js 静态资源。
3. 通过环境变量控制部署目标（`ENV=dev/testnet`），合约部署需人工审批。

### 6.4.1 Epic 2 持续集成要求
- **Move**：在 `move-test` 阶段新增订单模块单元测试与状态机回归，确保 Story 2.1 覆盖。
- **Backend**：执行 `pnpm --filter @haigo/bff test -- --runInBand`，包含订单 API 与媒体验证集成测试。
- **Frontend**：新增端到端测试，验证订单创建流程与媒体验证 UI；可使用 Playwright，命令建议 `pnpm --filter @haigo/web test:e2e`。
- **Artifact**：BFF 镜像需包含静态媒体托管（Nginx/Express）能力，或在部署脚本中附带对象存储配置。

## 6.5 基础设施即代码
- Terraform 管理 ECS、RDS（Postgres）、OSS Bucket（预留）、安全组；若暂未接入 Terraform，可用阿里云 ROS 模板起步。
- Ansible/Shell 脚本负责 BFF/Hasura 服务的容器化部署与环境变量注入。

### 6.5.1 Epic 2 补充资源
- **对象存储**：Terraform 模块需创建 OSS Bucket、STS 角色与访问策略，允许 `putObject`/`getObject`/`deleteObject`。同时创建日志 Bucket 记录访问。
- **消息与队列（可选）**：若未来将订单监听迁移至独立 Processor，可在 IaC 中预设 RocketMQ / Kafka 资源，BFF 消费聚合数据。
- **Secret 管理**：统一在 Terraform 中写入 `MEDIA_SIGNING_KEY`、`APTOS_MODULE_ADDRESS` 等敏感字段，部署时注入到容器。

## 6.6 Epic 2 验收检查表（部署视角）

| Story | 部署要点 | 验证方法 |
|-------|----------|----------|
| 2.1 | Move 模块部署成功，订单事件可产出 | Forge/CLI 执行完整状态机交易，确认事件在 Indexer 可查询 |
| 2.2 | 前端订单创建页面指向最新 BFF 与合约地址 | 通过测试账户创建订单，验证费用拆解与 `record_uid` 显示 |
| 2.3 | 媒体上传/校验服务可用，哈希一致 | 上传样例图片，调用 `/api/orders/:recordUid/media-verify`，比对结果 `verified=true` |
| 2.4 | 订单时间线与出库流程闭环，监听指标正常 | 在 BFF 指标面板检查游标推进；前端订单详情展示全流程时间线 |

# 6. 部署与环境

## 6.0 包管理与构建流程

> 目标：保证 Monorepo 在不同环境（本地、测试网、生产）中具备可重复的安装、构建与启动顺序。

### 6.0.1 Workspace 初始化

1. **安装依赖**：`pnpm install`
2. **校验 Node 版本**：Node ≥ 18（建议 20 LTS），确保原生 ESM 与 `fetch` 可用。
3. **安装全局工具**（可选）：`aptos` CLI、`hasura-cli`、`prisma` 等便于本地调试。

### 6.0.2 标准构建流水线

```bash
pnpm --filter @haigo/shared build   # 1. 共享 DTO/配置 编译到 dist/
pnpm --filter @haigo/bff build      # 2. NestJS BFF (NodeNext)
pnpm --filter @haigo/web build      # 3. Next.js 前端
```

- `packages/shared` 产物位于 `dist/`，被其它 workspace 通过 `exports` 引用。
- BFF/Web 需在构建前确保共享包完成编译，否则会出现 “Cannot find module '@haigo/shared/…'” 的编译错误。
- CI/CD 可使用 `pnpm -r build --filter ...` 根据环境拆分阶段。

### 6.0.3 开发模式

| 服务 | 命令 | 说明 |
|------|------|------|
| 全量 | `pnpm dev` | 并行启动 Web 与 BFF（仍需预先运行 Docker 服务）。 |
| Web  | `pnpm --filter @haigo/web dev` | Next.js dev server，自动读取 `.env.local`。 |
| BFF  | `pnpm --filter @haigo/bff start:dev` | 使用 `tsx watch` 执行 ESM 入口，自动处理 `.js` 扩展与热重载。 |
| Shared | `pnpm --filter @haigo/shared build --watch` | 可选：若频繁修改 DTO，可临时开启 watch（需手动在 `package.json` 添加 watch 脚本）。 |

> **注意**：`tsx` 基于 esbuild，需要 Node ≥ 18 与工作目录可写缓存；首次启动会下载平台二进制，如遇权限问题请清理 `node_modules/.pnpm/esbuild@*/node_modules/esbuild` 并重装。

### 6.0.4 运行顺序建议

```text
+------------+    +--------------------+    +-----------------+
|  Docker    | -> |  pnpm dev:bff      | -> |  pnpm dev:web    |
|  (DB/GQL)  |    |  (watch + Prisma)  |    |  (Next.js HMR)   |
+------------+    +--------------------+    +-----------------+
        |                     ^                        ^
        +---- Shared DTO dist +------------+------------+
                             |
                   pnpm --filter @haigo/shared build
```

### 6.0.5 环境变量与配置文件

- 统一使用 `.env`（BFF）、`.env.local`（Web）、`.env`（Docker/Hasura）管理。
- 共享配置放在 `packages/shared/src/config`，构建后经 `dist/config/*.js` 暴露。
- 建议使用 `dotenv-flow` 或 GitHub Actions Secrets 注入，不直接提交 `.env` 至仓库。

## 6.1 本地 Docker PoC 环境（Postgres + Hasura）

> PoC 阶段我们仅将 **Postgres** 与 **Hasura** 放入 Docker，确保数据库与 GraphQL 元数据在团队内一致；BFF、Web 仍在宿主机运行，方便热更新与调试。

### 6.1.1 前置依赖

| 项目 | 说明 |
| ---- | ---- |
| Docker Engine ≥ 24 | 推荐安装 Docker Desktop（macOS/Windows）或原生 Docker CE（Linux）。 |
| Docker Compose V2 | 随 Docker Desktop 自带，Linux 可通过 `docker compose version` 验证。 |
| pnpm ≥ 8.15 | 宿主机运行 Node 服务与脚本。 |
| Hasura CLI ≥ v2.44 | 导入 metadata，命令：`npm install -g hasura-cli`。 |
| Node.js ≥ 18 | 宿主机运行 BFF、Web 及工具链。 |

### 6.1.2 Compose 模板

`docker/compose.poc.yml`（仓库已提供示例）仅包含数据库与 Hasura：

```yaml
services:
  postgres:
    image: postgres:15
    container_name: haigo-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: haigo
      POSTGRES_PASSWORD: haigo
      POSTGRES_DB: haigo
    ports:
      - "5433:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data

  hasura:
    image: hasura/graphql-engine:v2.44.0
    container_name: haigo-hasura
    restart: unless-stopped
    depends_on:
      - postgres
    ports:
      - "8080:8080"
    environment:
      HASURA_GRAPHQL_DATABASE_URL: postgres://haigo:haigo@postgres:5432/haigo
      HASURA_GRAPHQL_ENABLE_CONSOLE: "true"
      HASURA_GRAPHQL_DEV_MODE: "true"
      HASURA_GRAPHQL_ADMIN_SECRET: haigo-secret
      HASURA_GRAPHQL_JWT_SECRET: '{"type":"HS256","key":"local-development-secret-key-32-bytes"}'

volumes:
  pg_data:
```

> 默认将容器端口映射为 `5433→5432`、`8080→8080`，避免与本地 Postgres 冲突；需要时可再自定义端口。

### 6.1.3 启动与健康检查

```bash
cd docker
docker compose -f compose.poc.yml up -d
docker compose -f compose.poc.yml ps
```

服务就绪的判定：
- `postgres` 状态为 `Up`；
- `hasura` 状态为 `Up (healthy)`，访问 http://localhost:8080/console 可登录（Admin Secret: `haigo-secret`）。

常用命令：

| 目标 | 命令 |
| ---- | ---- |
| 查看服务日志 | `docker compose -f compose.poc.yml logs -f hasura` |
| 进入数据库容器 | `docker exec -it haigo-postgres psql -U haigo haigo` |
| 重启 Hasura | `docker compose -f compose.poc.yml restart hasura` |
| 停止并移除环境 | `docker compose -f compose.poc.yml down --remove-orphans` |
| 清空数据库数据 | `docker volume rm docker_pg_data` |

### 6.1.4 数据初始化

1. **Prisma 迁移（宿主机执行）**
   ```bash
   export DATABASE_URL="postgres://haigo:haigo@localhost:5433/haigo"
   pnpm --filter @haigo/bff prisma:migrate:deploy
   ```
   迁移完成后确认 `MEDIA_STORAGE_DIR`（默认 `./storage/media`）指向可写目录，必要时执行 `mkdir -p storage/media && chmod 755 storage/media`。
   如需重置数据库：`pnpm --filter @haigo/bff prisma migrate reset` 或删除卷。

2. **Hasura Metadata 导入**
   ```bash
   export HASURA_GRAPHQL_ENDPOINT="http://localhost:8080"
   export HASURA_GRAPHQL_ADMIN_SECRET="haigo-secret"

   hasura metadata apply \
     --project hasura \
     --endpoint "$HASURA_GRAPHQL_ENDPOINT" \
     --admin-secret "$HASURA_GRAPHQL_ADMIN_SECRET"
   ```
   导入后可在 Hasura Console 检查 `accounts` 等表、权限配置与 Query Collection。

### 6.1.5 常见问题

1. **端口冲突**：默认 `5433:5432` 已规避常见冲突，如仍占用可改成 `5434:5432` 等；Hasura 端口同理。
2. **Hasura 连不上数据库**：确认环境变量 `HASURA_GRAPHQL_DATABASE_URL` 是否与 Postgres 账号匹配，必要时查看 `docker compose logs hasura`。
3. **Prisma 连接失败**：确认宿主机 `DATABASE_URL` 指向 `localhost:5433`，并已执行迁移。
4. **元数据不一致**：重新运行 Hasura CLI 导入，或执行 `hasura metadata reload`。

### 6.1.6 Epic 2 附加组件：订单监听与媒体存储

为满足 Epic 2 的订单生命周期与媒体存证需求，本地环境需补充以下组件与准备步骤：

- **对象存储 / 媒体目录**：
  - PoC 可继续使用本地文件系统，执行 `mkdir -p storage/media` 并在 `.env` 内配置 `MEDIA_STORAGE_DIR=./storage/media`（可选 `MEDIA_PUBLIC_PREFIX=/media` 暴露静态路径）。
  - 若需模拟 Story 2.3 的对象存储，可新增 MinIO 服务（端口 `9000/9001`），并在 BFF 配置 `MEDIA_STORAGE_ENDPOINT`、`MEDIA_BUCKET`。上传凭证由 BFF 统一管理。
- **媒体静态访问**：使用 Nginx 或 Node 静态服务暴露 `storage/media`，以便前端轮询哈希校验。PoC 示例：`pnpm --filter @haigo/bff serve:media`（待补齐脚本）。
- **订单事件监听**：BFF 在启动时会并行运行 `AccountsEventListener` 与计划中的 `OrdersEventListener`。确保 `ORDER_INGESTOR_INTERVAL_MS`、`ORDER_INGESTOR_PAGE_SIZE` 环境变量已设置，避免默认值导致索引过慢。
- **本地调试数据**：Story 2.x 依赖链上事件；本地可通过 `scripts/seed-orders.ts`（计划新增）或测试网真实数据驱动。若暂未有脚本，可使用 Aptos CLI 手动发送订单相关交易，再由监听服务回放。

> 建议将 MinIO/静态服务单独写入 `docker/compose.media.yml`，通过 `docker compose -f compose.poc.yml -f compose.media.yml up -d` 启动，避免污染基础数据库栈。

## 6.2 宿主机运行 BFF 与 Web

- **启动命令**：
  ```bash
  pnpm --filter @haigo/bff start:dev
  pnpm --filter @haigo/web dev
  ```
- **关键环境变量**：
  - BFF：`DATABASE_URL=postgres://haigo:haigo@localhost:5433/haigo`、`HASURA_URL=http://localhost:8080`、`APTOS_INDEXER_URL=https://api.testnet.aptoslabs.com/v1/graphql`。
  - Web：`NEXT_PUBLIC_BFF_URL=http://localhost:3001`、`NEXT_PUBLIC_HASURA_URL=http://localhost:8080/v1/graphql`、`NEXT_PUBLIC_APTOS_INDEXER_URL=https://api.testnet.aptoslabs.com/v1/graphql`。
- **测试**：Story 1.4 要求在此环境下运行 `pnpm --filter @haigo/bff test` 并确保通过；必要时可使用 `pnpm --filter @haigo/bff lint` 做静态检查。

### 6.2.1 Epic 2 运行参数与服务约定
> 以下配置为 Epic 2+ 规划内容，代码尚未实现，保留用于后续迭代对齐。
- **新增 BFF 环境变量**：
  | 变量 | 默认值 | 说明 | 关联 Story |
  |------|--------|------|------------|
  | `ORDER_INGESTOR_INTERVAL_MS` | `30000` | 订单事件轮询间隔（毫秒） | 2.1 / 2.4 |
  | `ORDER_INGESTOR_PAGE_SIZE` | `50` | 单次抓取事件数量 | 2.1 |
  | `MEDIA_MAX_FILE_MB` | `200` | 上传文件最大限制（前后端统一） | 2.3 |
  | `MEDIA_STORAGE_ENDPOINT` | `http://localhost:9000` | MinIO/S3 访问地址 | 2.3 |
  | `MEDIA_STORAGE_BUCKET` | `haigo-media` | 媒体存储桶名称 | 2.3 |
  | `MEDIA_SIGNING_KEY` | _自定义_ | 生成上传签名的服务端密钥 | 2.3 |
  | `APTOS_MODULE_ADDRESS` | _部署输出_ | 订单/质押等 Move 模块地址 | 2.1 |
- **服务初始化**：BFF 启动后将：
  1. 校验对象存储可写入（若配置了 MinIO/S3）。
  2. 启动订单与账户事件监听器，打印最近游标，方便排查。
  3. 暴露 `/api/orders` 与 `/api/media/uploads` 端点；若缺少配置则在启动日志中给出警告。
- **前端依赖**：前端需要新增 `.env.local` 变量 `NEXT_PUBLIC_MEDIA_VERIFY_URL` 指向 BFF 的媒体验证接口，并在订单表单中读取 `MEDIA_MAX_FILE_MB` 与费用参数。
- **本地验证流程**：
  1. 通过 Move 脚本创建测试订单或使用测试网交易。
  2. 前端调用 `/api/orders/:recordUid/media-verify` 上传媒体。
  3. BFF 返回哈希匹配结果，并在 Hasura 中可查询对应订单记录。

## 6.3 测试网环境
- Aptos 合约部署到测试网，模块地址写入 `packages/shared/config/aptos.ts`。
- BFF 与 Hasura 可部署在单台云主机或 Kubernetes 节点（阿里云 ECS/ACK），开启 HTTPS。
- 媒体目录挂载云盘（ESSD），每日利用 OSS 同步脚本备份。

### 6.3.1 Move 模块部署（Story 2.1）
- 准备 `aptos` CLI，确保本地配置对应测试网账户。
- 执行 `pnpm --filter @haigo/move build`、`pnpm --filter @haigo/move test` 验证，通过后运行 `pnpm --filter @haigo/move deploy:testnet`（脚本需提供部署地址输出）。
- 记录新的 `orders`, `registry`, `reputation` 模块地址，写入：
  - `packages/shared/config/aptos.ts`
  - `apps/bff/.env` (`APTOS_MODULE_ADDRESS`)
  - `apps/web/.env.local`
- 部署完成后运行一次 `aptos move run` 或 `scripts/orders/mock_flow.move`（计划）以生成基准订单数据，便于链下监听初始化。

### 6.3.2 媒体存储与对象服务（Story 2.3）
- 生产/测试环境推荐使用阿里云 OSS；若仍在 PoC，可使用 MinIO 或 Ceph S3。配置项：
  - IAM/STS 凭证存放在云端 Secret Manager，通过容器环境变量注入。
  - 媒体文件命名规范：`{record_uid}/{event_type}/{originalName}`。
  - 采用生命周期规则自动清理超过 `90` 天未匹配的临时文件。
- 配置 CDN 或 CloudFront 加速访问，避免前端在媒体验证时遭遇跨域或网络瓶颈。

### 6.3.3 订单索引与监控（Story 2.4）
- 为 BFF 部署 Prometheus/Grafana 指标：`order_listener_last_version`、`order_listener_error_total`。
- 配置告警规则：监听超过 10 分钟无新事件或错误率 > 5% 时通知运营。
- 定期（CRON）运行 `scripts/backfill-order-media.ts`，补齐链上存在但链下缺失的媒体记录。

## 6.4 CI/CD
1. GitHub Actions（或阿里云流水线）三阶段：`move-test`、`backend-test`、`frontend-build`。
2. 构建产物：Move 模块 `build/`、BFF Docker 镜像、Next.js 静态资源。
3. 通过环境变量控制部署目标（`ENV=dev/testnet`），合约部署需人工审批。

### 6.4.1 Epic 2 持续集成要求
- **Move**：在 `move-test` 阶段新增订单模块单元测试与状态机回归，确保 Story 2.1 覆盖。
- **Backend**：执行 `pnpm --filter @haigo/bff test -- --runInBand`，包含订单 API 与媒体验证集成测试。
- **Frontend**：新增端到端测试，验证订单创建流程与媒体验证 UI；可使用 Playwright，命令建议 `pnpm --filter @haigo/web test:e2e`。
- **Artifact**：BFF 镜像需包含静态媒体托管（Nginx/Express）能力，或在部署脚本中附带对象存储配置。

## 6.5 基础设施即代码
- Terraform 管理 ECS、RDS（Postgres）、OSS Bucket（预留）、安全组；若暂未接入 Terraform，可用阿里云 ROS 模板起步。
- Ansible/Shell 脚本负责 BFF/Hasura 服务的容器化部署与环境变量注入。

### 6.5.1 Epic 2 补充资源
- **对象存储**：Terraform 模块需创建 OSS Bucket、STS 角色与访问策略，允许 `putObject`/`getObject`/`deleteObject`。同时创建日志 Bucket 记录访问。
- **消息与队列（可选）**：若未来将订单监听迁移至独立 Processor，可在 IaC 中预设 RocketMQ / Kafka 资源，BFF 消费聚合数据。
- **Secret 管理**：统一在 Terraform 中写入 `MEDIA_SIGNING_KEY`、`APTOS_MODULE_ADDRESS` 等敏感字段，部署时注入到容器。

## 6.6 Epic 2 验收检查表（部署视角）

| Story | 部署要点 | 验证方法 |
|-------|----------|----------|
| 2.1 | Move 模块部署成功，订单事件可产出 | Forge/CLI 执行完整状态机交易，确认事件在 Indexer 可查询 |
| 2.2 | 前端订单创建页面指向最新 BFF 与合约地址 | 通过测试账户创建订单，验证费用拆解与 `record_uid` 显示 |
| 2.3 | 媒体上传/校验服务可用，哈希一致 | 上传样例图片，调用 `/api/orders/:recordUid/media-verify`，比对结果 `verified=true` |
| 2.4 | 订单时间线与出库流程闭环，监听指标正常 | 在 BFF 指标面板检查游标推进；前端订单详情展示全流程时间线 |
